import llm
from fetch_data import DataFetcher
from random import choice
from text_summary import summarize_text

class SECAgent:
    def __init__(self, ticker, localmodel=False):
        self.ticker = ticker
        self.model = "llama3-8b-8192" #"mixtral-8x7b-32768" #"llama-3.1-70b-versatile"
        self.localmodel = localmodel
        self.data = [DataFetcher().get10k_1A(self.ticker),
                     DataFetcher().get10k_5(self.ticker),
                     #DataFetcher().get10k_6(self.ticker),
                     DataFetcher().get10k_7(self.ticker),
                     DataFetcher().get10k_7A(self.ticker),
                     DataFetcher().get10k_8(self.ticker)]
        

    def cleanData(self):
        #before analyzing, exclude the items witch are just Errors

        self.data = [d for d in self.data if isinstance(d, str) and d != "Error"]

    def generateResponse(self):

        self.cleanData()

        #if after the cleaning process self.data is empty, exit the function
        if len(self.data) == 0:
            return None
        
        data_raw =choice(self.data) #random item from the 10-K report
        data = summarize_text(data_raw)

        """
        function that generates a response to a given prompt using the Groq API
        It takes a random item from the 10-K report and generates a response to it
        Returns:
        res: str, the generated response
        """

        

        prompt = f"""
        You are an expert financial analyst at reading SEC filings and drawing conclusions that only a PhD level quant can draw.
        You are given an unstructured part of an SEC 10K/10Q and your job is to carefully read it, and extract some kind of a unique insight.
        We are going to use these insights to make decisions about building a rating (buy, hold, sell) for the stock.
        You have to be technical, quantitative, use numbers, and most of all, creative. You cannot act like a 2 year old.

        Here is the data dump:
        ```
        {data}
        ```

        Now return a one paragraph insights from this data. Add a heading/title in the first line. The heading should explain the paragraph, should not be generic. For instance, a title like `AAPL's next support is at 138' is better than 'AAPL's support levels'
        No prefix, suffix, starting with `here is`, etc. Start directly with insights. Use numbers and statistics where you can, but not graphs.
        """

        if self.localmodel:
            result = llm.generateResponseLocally(prompt)
        else:
            result = llm.generateResponse(prompt, model=self.model)
        return result
    
    def generateResponse_chunks(self):
        """
        the aim is to divide the data into chunks and generate a response for each chunk
        at the end the final text is generated by combining all the responses
        """
        data = choice(self.data) #random item from the 10-K report

        #split the data into chunks of 1000 characters
        prompt_initial = """
            You are an expert financial analyst at reading SEC filings and drawing conclusions that only a PhD level quant can draw.
            You are given an unstructured part of an SEC 10K/10Q and your job is to carefully read it, and extract some kind of a unique insight.
            We are going to use these insights to make decisions about building a rating (buy, hold, sell) for the stock.
            You have to be technical, quantitative, use numbers, and most of all, creative.

            Here is the data dump:
            ```
            {%s}
            ```

            Now return a one paragraph insights from this data. Add a heading/title in the first line. The heading should explain the paragraph, should not be generic. For instance, a title like `AAPL's next support is at 138' is better than 'AAPL's support levels'
            **No notes, comments, prefix, suffix, starting with `here is`, etc. Start directly with insights. Use numbers and statistics where you can, but not graphs.**
            """
        initial = False
        final_text = ""
        prompt=""
        for i in range(0, len(data), 1000):
            chunk = data[i:i+1000]
            if not initial:
                prompt = prompt_initial % chunk
                initial = True

            else:
                prompt = "Now, you have got more information to work with. Extract the relevant data from the following text and integrate it with the previous insights. The integration has to be fluent and the final text has to be continuous. Don't separate the two text but merge them into one. **No notes, comments, prefix, suffix, starting with `here is`, etc. Start directly with insights. Use numbers and statistics where you can, but not graphs.** The data dump is as follows:\n```\n{%s}\n```\n" % chunk

            if self.localmodel:
                result = llm.generateResponseLocally(prompt)
            else:
                result = llm.generateResponse(prompt, model=self.model)
            final_text = result 

        return final_text